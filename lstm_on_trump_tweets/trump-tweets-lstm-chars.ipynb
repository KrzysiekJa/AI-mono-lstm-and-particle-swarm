{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/asl_data/sign_mnist_train.csv\n",
      "data/asl_data/sign_mnist_valid.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data/asl_data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>insult</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>thomas-frieden</td>\n",
       "      <td>fool</td>\n",
       "      <td>Can you believe this fool, Dr. Thomas Frieden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>thomas-frieden</td>\n",
       "      <td>DOPE</td>\n",
       "      <td>Can you believe this fool, Dr. Thomas Frieden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>politicians</td>\n",
       "      <td>all talk and no action</td>\n",
       "      <td>Big time in U.S. today - MAKE AMERICA GREAT AG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>ben-cardin</td>\n",
       "      <td>It's politicians like Cardin that have destroy...</td>\n",
       "      <td>Politician @SenatorCardin didn't like that I s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-06-24</td>\n",
       "      <td>neil-young</td>\n",
       "      <td>total hypocrite</td>\n",
       "      <td>For the nonbeliever, here is a photo of @Neily...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>10356</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2020-election</td>\n",
       "      <td>Many States want to decertify the mistake they...</td>\n",
       "      <td>If Vice President @Mike_Pence comes through fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>10357</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2020-election</td>\n",
       "      <td>based on irregularities and fraud, plus corrup...</td>\n",
       "      <td>States want to correct their votes, which they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10357</th>\n",
       "      <td>10358</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2020-election</td>\n",
       "      <td>Our Election Process is worse than that of thi...</td>\n",
       "      <td>They just happened to find 50,000 ballots late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10358</th>\n",
       "      <td>10359</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2020-election</td>\n",
       "      <td>a FRAUD</td>\n",
       "      <td>The States want to redo their votes. They foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10359</th>\n",
       "      <td>10360</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>chuck-todd</td>\n",
       "      <td>Sleepy Eyes,  Sad to watch!</td>\n",
       "      <td>Sleepy Eyes Chuck Todd is so happy with the fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10360 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        date          target  \\\n",
       "0               1  2014-10-09  thomas-frieden   \n",
       "1               2  2014-10-09  thomas-frieden   \n",
       "2               3  2015-06-16     politicians   \n",
       "3               4  2015-06-24      ben-cardin   \n",
       "4               5  2015-06-24      neil-young   \n",
       "...           ...         ...             ...   \n",
       "10355       10356  2021-01-06   2020-election   \n",
       "10356       10357  2021-01-06   2020-election   \n",
       "10357       10358  2021-01-06   2020-election   \n",
       "10358       10359  2021-01-06   2020-election   \n",
       "10359       10360  2021-01-06      chuck-todd   \n",
       "\n",
       "                                                  insult  \\\n",
       "0                                                   fool   \n",
       "1                                                   DOPE   \n",
       "2                                 all talk and no action   \n",
       "3      It's politicians like Cardin that have destroy...   \n",
       "4                                        total hypocrite   \n",
       "...                                                  ...   \n",
       "10355  Many States want to decertify the mistake they...   \n",
       "10356  based on irregularities and fraud, plus corrup...   \n",
       "10357  Our Election Process is worse than that of thi...   \n",
       "10358                                            a FRAUD   \n",
       "10359                        Sleepy Eyes,  Sad to watch!   \n",
       "\n",
       "                                                   tweet  \n",
       "0      Can you believe this fool, Dr. Thomas Frieden ...  \n",
       "1      Can you believe this fool, Dr. Thomas Frieden ...  \n",
       "2      Big time in U.S. today - MAKE AMERICA GREAT AG...  \n",
       "3      Politician @SenatorCardin didn't like that I s...  \n",
       "4      For the nonbeliever, here is a photo of @Neily...  \n",
       "...                                                  ...  \n",
       "10355  If Vice President @Mike_Pence comes through fo...  \n",
       "10356  States want to correct their votes, which they...  \n",
       "10357  They just happened to find 50,000 ballots late...  \n",
       "10358  The States want to redo their votes. They foun...  \n",
       "10359  Sleepy Eyes Chuck Todd is so happy with the fa...  \n",
       "\n",
       "[10360 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/trump_insult_tweets_2014_to_2021.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Can you believe this fool, Dr. Thomas Frieden ...\n",
       "1        Can you believe this fool, Dr. Thomas Frieden ...\n",
       "2        Big time in U.S. today - MAKE AMERICA GREAT AG...\n",
       "3        Politician @SenatorCardin didn't like that I s...\n",
       "4        For the nonbeliever, here is a photo of @Neily...\n",
       "                               ...                        \n",
       "10355    If Vice President @Mike_Pence comes through fo...\n",
       "10356    States want to correct their votes, which they...\n",
       "10357    They just happened to find 50,000 ballots late...\n",
       "10358    The States want to redo their votes. They foun...\n",
       "10359    Sleepy Eyes Chuck Todd is so happy with the fa...\n",
       "Name: tweet, Length: 10360, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df['tweet']\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10360,)\n",
      "(10360,)\n",
      "(5673,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                                                  5673\n",
       "unique                                                 5673\n",
       "top       Our Justice Department must not let Awan & Deb...\n",
       "freq                                                      1\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tweets.shape)\n",
    "tweets.dropna(inplace=True)\n",
    "print(tweets.shape)\n",
    "tweets.drop_duplicates(inplace=True)\n",
    "print(tweets.shape)\n",
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXjUlEQVR4nO3df4xc11338fcHp0ncbrGTuAzBtp51wBSZLBRnSIKKqtkGUietcJBC5WBau3K1ApwSqKvGoYL0gSd6XHhM1KglaMFWHVplE0IhJj9IjZtVVAnnh0uStRNCtqnbeuXapHEM27o/tnyfP+7xZrqd2R8zO7MzPp+XtNp7zzlz7zl7737mzp07cxURmJlZHn5koTtgZmbt49A3M8uIQ9/MLCMOfTOzjDj0zcwycs5Cd2A6y5Yti97e3sn5b37zm7zhDW9YuA7NM4+ns3k8nc3jqe/gwYMvR8SbatV1dOj39vby1FNPTc4PDw9TqVQWrkPzzOPpbB5PZ/N46pP0lXp1Pr1jZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpaRGT+RK2k38C7gRERcWlX+AWAr8H3gwYj4cCq/BdiSyn8vIh5J5euAjwOLgL+JiB3zPBbLUO/2B1u27G19E2yeZvlHdryzZes2a5XZfA3Dp4BPAHedKZDUD6wHfj4iviPpx1L5GmAD8LPATwD/Iumn08M+CfwqcBR4UtLeiHhuvgZiZmYzmzH0I+IxSb1Tin8H2BER30ltTqTy9cBQKv+ypFHg8lQ3GhEvAUgaSm0d+mZmbaTZ3CM3hf4DZ07vSHoauB9YB3wb+FBEPCnpE8CBiPh0arcLeDgtZl1EvD+Vvwe4IiJurLGuAWAAoFQqXTY0NDRZNz4+Tk9PT2Mj7UAeT/NGxk61bNmlxXD8dP36vuVLWrbuVvD+1tnmczz9/f0HI6Jcq67Rb9k8B7gQuBL4ReBeSZc0uKwfEBGDwCBAuVyO6m+d87fqdbaFGM9059ybta1vgp0j9f9FjmystGzdreD9rbO1azyNhv5R4LNRvEx4QtL/AMuAMWBlVbsVqYxpys3MrE0avWTzH4F+gPRG7bnAy8BeYIOk8yStAlYDTwBPAqslrZJ0LsWbvXub7LuZmc3RbC7ZvBuoAMskHQVuBXYDuyUdAr4LbEpH/Ycl3UvxBu0EsDUivp+WcyPwCMUlm7sj4nALxmNmZtOYzdU7N9Sp+q067W8DbqtR/hDw0Jx6Z2Zm88qfyDUzy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDIyY+hL2i3pRLpL1tS6bZJC0rI0L0l3SBqV9KyktVVtN0l6Mf1smt9hmJnZbMzmSP9TwLqphZJWAlcDX60qvobivrirgQHgztT2QorbLF4BXA7cKumCZjpuZmZzN2PoR8RjwCs1qm4HPgxEVdl64K4oHACWSroYeAewLyJeiYiTwD5qPJGYmVlrzXiP3FokrQfGIuIZSdVVy4GvVc0fTWX1ymste4DiVQKlUonh4eHJuvHx8R+Y73YeT/O29U20bNmlxdMvv9u2nfe3ztau8cw59CW9HvhDilM78y4iBoFBgHK5HJVKZbJueHiY6vlu5/E0b/P2B1u27G19E+wcqf8vcmRjpWXrbgXvb52tXeNp5OqdnwRWAc9IOgKsAL4o6ceBMWBlVdsVqaxeuZmZtdGcQz8iRiLixyKiNyJ6KU7VrI2IrwN7gfemq3iuBE5FxDHgEeBqSRekN3CvTmVmZtZGs7lk827gX4E3Szoqacs0zR8CXgJGgb8GfhcgIl4B/hR4Mv38SSozM7M2mvGcfkTcMEN9b9V0AFvrtNsN7J5j/8zMbB75E7lmZhlp6JJNM7Nc9LbwCrFq2/omfuBqtCM73tmS9fhI38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDIym9sl7pZ0QtKhqrI/l/Tvkp6V9A+SllbV3SJpVNILkt5RVb4ulY1K2j7vIzEzsxnN5kj/U8C6KWX7gEsj4ueA/wBuAZC0BtgA/Gx6zF9KWiRpEfBJ4BpgDXBDamtmZm00Y+hHxGPAK1PKPhcRE2n2ALAiTa8HhiLiOxHxZYobpF+efkYj4qWI+C4wlNqamVkbqbiX+QyNpF7ggYi4tEbdPwH3RMSnJX0COBARn051u4CHU9N1EfH+VP4e4IqIuLHG8gaAAYBSqXTZ0NDQZN34+Dg9PT1zG2EH83iaNzJ2qmXLLi2G46fr1/ctX9KydbeC97fGtHIfqzZ1f2tm/+rv7z8YEeVadU3dI1fSR4AJ4DPNLKdaRAwCgwDlcjkqlcpk3fDwMNXz3c7jad7mFt6/dFvfBDtH6v+LHNlYadm6W8H7W2NauY9Vm7q/tWr/ajj0JW0G3gVcFa+9XBgDVlY1W5HKmKbczMzapKFLNiWtAz4M/FpEfKuqai+wQdJ5klYBq4EngCeB1ZJWSTqX4s3evc113czM5mrGI31JdwMVYJmko8CtFFfrnAfskwTFefzfjojDku4FnqM47bM1Ir6flnMj8AiwCNgdEYdbMB4zM5vGjKEfETfUKN41TfvbgNtqlD8EPDSn3pmZ2bzyJ3LNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMzBj6knZLOiHpUFXZhZL2SXox/b4glUvSHZJGJT0raW3VYzal9i9K2tSa4ZiZ2XRmc6T/KWDdlLLtwP6IWA3sT/MA11DcF3c1MADcCcWTBMVtFq8ALgduPfNEYWZm7TNj6EfEY8ArU4rXA3vS9B7guqryu6JwAFgq6WLgHcC+iHglIk4C+/jhJxIzM2sxRcTMjaRe4IGIuDTNvxoRS9O0gJMRsVTSA8COiPhCqtsP3ExxY/XzI+L/pPI/Ak5HxP+rsa4BilcJlEqly4aGhibrxsfH6enpaXiwncbjad7I2KmWLbu0GI6frl/ft3xJy9bdCt7fGtPKfaza1P2tmf2rv7//YESUa9XNeGP0mURESJr5mWP2yxsEBgHK5XJUKpXJuuHhYarnu53H07zN2x9s2bK39U2wc6T+v8iRjZWWrbsVvL81ppX7WLWp+1ur9q9Gr945nk7bkH6fSOVjwMqqditSWb1yMzNro0ZDfy9w5gqcTcD9VeXvTVfxXAmciohjwCPA1ZIuSG/gXp3KzMysjWY8vSPpbopz8sskHaW4CmcHcK+kLcBXgHen5g8B1wKjwLeA9wFExCuS/hR4MrX7k4iY+uawmZm12IyhHxE31Km6qkbbALbWWc5uYPecemdmZvPKn8g1M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8tIU6Ev6Q8kHZZ0SNLdks6XtErS45JGJd0j6dzU9rw0P5rqe+dlBGZmNmsNh76k5cDvAeWIuBRYBGwAPgbcHhE/BZwEtqSHbAFOpvLbUzszM2ujGe+RO4vHL5b0PeD1wDHg7cBvpvo9wEeBO4H1aRrgPuATkpTuq2tmVlfv9gd/qGxb3wSba5Tb9NRM5kq6CbgNOA18DrgJOJCO5pG0Eng4Ii6VdAhYFxFHU92XgCsi4uUpyxwABgBKpdJlQ0NDk3Xj4+P09PQ03N9O4/E0b2TsVMuWXVoMx0/Xr+9bvqRl626Fbt7fam3nmbZPt5k6nmb2r/7+/oMRUa5V1/CRvqQLKI7eVwGvAn8HrGt0eWdExCAwCFAul6NSqUzWDQ8PUz3f7Tye5rXySG9b3wQ7R+r/ixzZWGnZuluhm/e3Wtt5pu3TbaaOp1X7VzNv5P4K8OWI+M+I+B7wWeCtwFJJZ3q+AhhL02PASoBUvwT4RhPrNzOzOWom9L8KXCnp9ZIEXAU8BzwKXJ/abALuT9N70zyp/vM+n29m1l4Nh35EPE7xhuwXgZG0rEHgZuCDkkaBi4Bd6SG7gItS+QeB7U3028zMGtDUCbGIuBW4dUrxS8DlNdp+G/iNZtZnZmbN8Sdyzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDQV+pKWSrpP0r9Lel7SL0m6UNI+SS+m3xektpJ0h6RRSc9KWjs/QzAzs9lq9kj/48A/R8TPAD8PPE9xG8T9EbEa2M9rt0W8BlidfgaAO5tct5mZzVHDoS9pCfA20j1wI+K7EfEqsB7Yk5rtAa5L0+uBu6JwAFgq6eJG129mZnOniGjsgdJbKG6E/hzFUf5B4CZgLCKWpjYCTkbEUkkPADsi4gupbj9wc0Q8NWW5AxSvBCiVSpcNDQ1N1o2Pj9PT09NQfzuRx9O8kbFTLVt2aTEcP12/vm/5kpatuxW6eX+rtZ1n2j7dZup4mtm/+vv7D0ZEuVZdMzdGPwdYC3wgIh6X9HFeO5UDQESEpDk9q0TEIMWTCeVyOSqVymTd8PAw1fPdzuNp3ubtD7Zs2dv6Jtg5Uv9f5MjGSsvW3QrdvL/V2s4zbZ9uM3U8rdq/mjmnfxQ4GhGPp/n7KJ4Ejp85bZN+n0j1Y8DKqsevSGVmZtYmDYd+RHwd+JqkN6eiqyhO9ewFNqWyTcD9aXov8N50Fc+VwKmIONbo+s3MbO6afW30AeAzks4FXgLeR/FEcq+kLcBXgHentg8B1wKjwLdSWzMza6OmQj8ingZqvVlwVY22AWxtZn1mZtYcfyLXzCwjDn0zs4ycPdc72YLq3f4g2/omWnoJpZk1z0f6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWWk6dCXtEjSv0l6IM2vkvS4pFFJ96RbKSLpvDQ/mup7m123mZnNzXwc6d8EPF81/zHg9oj4KeAksCWVbwFOpvLbUzszM2ujpkJf0grgncDfpHkBbwfuS032ANel6fVpnlR/VWpvZmZtouJ+5Q0+WLoP+L/AG4EPAZuBA+loHkkrgYcj4lJJh4B1EXE01X0JuCIiXp6yzAFgAKBUKl02NDQ0WTc+Pk5PT0/D/e00Z9N4RsZOUVoMx08vdE/mz0zj6Vu+pH2dmQfdvL+NjJ36obKzfX9rZv/q7+8/GBHlWnUN3y5R0ruAExFxUFKl0eVMFRGDwCBAuVyOSuW1RQ8PD1M93+3OpvFsTrdL3Dly9tyBc6bxHNlYaV9n5kE372+1bsN5tu9vrdq/mvmLvRX4NUnXAucDPwp8HFgq6ZyImABWAGOp/RiwEjgq6RxgCfCNJtZvZmZz1PA5/Yi4JSJWREQvsAH4fERsBB4Frk/NNgH3p+m9aZ5U//lo5tySmZnNWSuu078Z+KCkUeAiYFcq3wVclMo/CGxvwbrNzGwa83JCLCKGgeE0/RJweY023wZ+Yz7WZ2ZmjfEncs3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLyNnzGWYza7neGl+HYN3FR/pmZhlx6JuZZcSnd8y6TKOnWLb1TdT8tkrLi0P/LONzrmY2HZ/eMTPLiI/0zRrkV1XWjXykb2aWEYe+mVlGHPpmZhlpOPQlrZT0qKTnJB2WdFMqv1DSPkkvpt8XpHJJukPSqKRnJa2dr0GYmdnsNHOkPwFsi4g1wJXAVklrKG6DuD8iVgP7ee22iNcAq9PPAHBnE+s2M7MGNHNj9GMR8cU0/d/A88ByYD2wJzXbA1yXptcDd0XhALBU0sWNrt/MzOZOEdH8QqRe4DHgUuCrEbE0lQs4GRFLJT0A7IiIL6S6/cDNEfHUlGUNULwSoFQqXTY0NDRZNz4+Tk9PT9P97RStGM/I2Kl5Xd5clBbD8dMLtvp55/F0trN9PH3LlzS8rP7+/oMRUa5V1/R1+pJ6gL8Hfj8i/qvI+UJEhKQ5PatExCAwCFAul6NSqUzWDQ8PUz3f7VoxnoX8mP22vgl2jpw9H/3weDrb2T6eIxsrLVlPU1fvSHodReB/JiI+m4qPnzltk36fSOVjwMqqh69IZWZm1iYNP02mUze7gOcj4i+qqvYCm4Ad6ff9VeU3ShoCrgBORcSxRtffyWb7SU1/AZaZtVszr43eCrwHGJH0dCr7Q4qwv1fSFuArwLtT3UPAtcAo8C3gfU2s28zMGtBw6Kc3ZFWn+qoa7QPY2uj6zMysef5ErplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRs6e287UMNvvtTczy4WP9M3MMuLQNzPLiEPfzCwjbQ99SeskvSBpVNL2dq/fzCxnbQ19SYuATwLXAGuAGyStaWcfzMxy1u4j/cuB0Yh4KSK+CwwB69vcBzOzbKm4X3mbViZdD6yLiPen+fcAV0TEjVVtBoCBNPtm4IWqRSwDXm5Td9vB4+lsHk9n83jq+18R8aZaFR13nX5EDAKDteokPRUR5TZ3qWU8ns7m8XQ2j6cx7T69MwasrJpfkcrMzKwN2h36TwKrJa2SdC6wAdjb5j6YmWWrrad3ImJC0o3AI8AiYHdEHJ7DImqe9uliHk9n83g6m8fTgLa+kWtmZgvLn8g1M8uIQ9/MLCNdE/pnw9c3SDoiaUTS05KeSmUXSton6cX0+4KF7mc9knZLOiHpUFVZzf6rcEfaXs9KWrtwPa+tzng+KmksbaOnJV1bVXdLGs8Lkt6xML2uTdJKSY9Kek7SYUk3pfKu3D7TjKdbt8/5kp6Q9Ewaz/9O5askPZ76fU+6wAVJ56X50VTfO2+diYiO/6F40/dLwCXAucAzwJqF7lcD4zgCLJtS9mfA9jS9HfjYQvdzmv6/DVgLHJqp/8C1wMOAgCuBxxe6/7Mcz0eBD9Vouybtd+cBq9L+uGihx1DVv4uBtWn6jcB/pD535faZZjzdun0E9KTp1wGPp7/7vcCGVP5XwO+k6d8F/ipNbwDuma++dMuR/tn89Q3rgT1peg9w3cJ1ZXoR8RjwypTiev1fD9wVhQPAUkkXt6Wjs1RnPPWsB4Yi4jsR8WVglGK/7AgRcSwivpim/xt4HlhOl26facZTT6dvn4iI8TT7uvQTwNuB+1L51O1zZrvdB1wlSfPRl24J/eXA16rmjzL9DtCpAvicpIPp6yYAShFxLE1/HSgtTNcaVq//3bzNbkynPHZXnW7rmvGkUwG/QHE02fXbZ8p4oEu3j6RFkp4GTgD7KF6NvBoRE6lJdZ8nx5PqTwEXzUc/uiX0zxa/HBFrKb5ldKukt1VXRvFarmuvoe32/id3Aj8JvAU4Buxc0N7MkaQe4O+B34+I/6qu68btU2M8Xbt9IuL7EfEWim8iuBz4mYXoR7eE/lnx9Q0RMZZ+nwD+gWLDHz/zsjr9PrFwPWxIvf535TaLiOPpn/N/gL/mtVMEHT8eSa+jCMjPRMRnU3HXbp9a4+nm7XNGRLwKPAr8EsVptTMfkq3u8+R4Uv0S4Bvzsf5uCf2u//oGSW+Q9MYz08DVwCGKcWxKzTYB9y9MDxtWr/97gfemq0SuBE5VnWboWFPOa/86xTaCYjwb0lUVq4DVwBPt7l896XzvLuD5iPiLqqqu3D71xtPF2+dNkpam6cXAr1K8T/EocH1qNnX7nNlu1wOfT6/UmrfQ72rP4d3vaynewf8S8JGF7k8D/b+E4uqCZ4DDZ8ZAcZ5uP/Ai8C/AhQvd12nGcDfFS+rvUZx/3FKv/xRXK3wyba8RoLzQ/Z/leP429ffZ9I93cVX7j6TxvABcs9D9nzKWX6Y4dfMs8HT6ubZbt8804+nW7fNzwL+lfh8C/jiVX0Lx5DQK/B1wXio/P82PpvpL5qsv/hoGM7OMdMvpHTMzmwcOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy8v8BWas0BpnkPs8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets.map(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "tweets = tweets.tolist()\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    tweets[i] = tweets[i].lower()\n",
    "    tweets[i] = re.sub(r'http\\S+', '', tweets[i]) #usuwanie linkow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Chars: 95\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(tweets))))\n",
    "\n",
    "print('Unique Chars:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chars:  ['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '=', '?', '@', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '\\x8f', '\\x9d', '\\xa0', 'Â¡', 'Â¦', 'Âµ', 'Â·', 'Â¸', 'Âº', 'Â½', 'Â¿', 'Ã¢', 'Ã¤', 'Ã©', 'Ã¯', 'Ã°', 'Ã´', 'Ã¶', 'Ã¹', 'Ãº', 'Ã¿', 'Å“', 'Å¾', 'Ëœ', 'â€“', 'â€”', 'â€˜', 'â€™', 'â€š', 'â€œ', 'â€', 'â€¡', 'â€¦', 'â‚¬', 'ðŸ˜‰', 'ðŸ˜§']\n"
     ]
    }
   ],
   "source": [
    "print('Chars: ', chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " '?',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " ' ',\n",
       " '!',\n",
       " ',',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_diff = chars[16:-38]\n",
    "chars_diff.remove(\"=\")\n",
    "chars_diff.remove(\"@\")\n",
    "chars_diff.append(' ')\n",
    "chars_diff.append(\"!\")\n",
    "chars_diff.append(\",\")\n",
    "chars_diff.append(\".\")\n",
    "chars_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in chars_diff:\n",
    "    chars.remove(i)\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    for c in chars:\n",
    "        tweets[i] = tweets[i].replace(c,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chars:  [' ', '!', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] \n",
      "Length:  43\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(tweets))))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print('Chars: ', chars, '\\nLength: ', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  1053641\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    text.append(''.join(map(str,[*tweets[i]])))\n",
    "\n",
    "text = ''.join(text)\n",
    "print(\"Length: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can you believe this fool, dr. thomas frieden of c'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 50\n",
    "Step_Size = 4\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - SEQUENCE_LENGTH, Step_Size):\n",
    "    sentences.append(text[i: i + SEQUENCE_LENGTH])\n",
    "    next_chars.append(text[i + SEQUENCE_LENGTH])\n",
    "\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263398, 50, 43) (263398, 43)\n"
     ]
    }
   ],
   "source": [
    "predictors = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
    "labels = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        predictors[i, t, char_indices[char]] = 1\n",
    "    labels[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print(predictors.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dropout(0.1))\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(len(chars) * 2, input_shape=(SEQUENCE_LENGTH, len(chars)), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(len(chars) * 10,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(len(chars) * 10))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "'''\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50, 86)            44720     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 86)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 430)           889240    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 430)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 430)               1480920   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 430)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 43)                18533     \n",
      "=================================================================\n",
      "Total params: 2,433,413\n",
      "Trainable params: 2,433,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4484/4484 [==============================] - 101s 23ms/step - loss: 2.1889 - accuracy: 0.3651 - val_loss: 1.7389 - val_accuracy: 0.4862\n",
      "Epoch 2/30\n",
      "4484/4484 [==============================] - 101s 23ms/step - loss: 1.5815 - accuracy: 0.5319 - val_loss: 1.5359 - val_accuracy: 0.5446\n",
      "Epoch 3/30\n",
      "4484/4484 [==============================] - 101s 23ms/step - loss: 1.4170 - accuracy: 0.5783 - val_loss: 1.4610 - val_accuracy: 0.5710\n",
      "Epoch 4/30\n",
      "4484/4484 [==============================] - 101s 23ms/step - loss: 1.3282 - accuracy: 0.6002 - val_loss: 1.4336 - val_accuracy: 0.5776\n",
      "Epoch 5/30\n",
      "4484/4484 [==============================] - 101s 23ms/step - loss: 1.2664 - accuracy: 0.6166 - val_loss: 1.4167 - val_accuracy: 0.5849\n",
      "Epoch 6/30\n",
      "4484/4484 [==============================] - 101s 23ms/step - loss: 1.2215 - accuracy: 0.6286 - val_loss: 1.4181 - val_accuracy: 0.5893\n",
      "Epoch 7/30\n",
      "4484/4484 [==============================] - 102s 23ms/step - loss: 1.1827 - accuracy: 0.6392 - val_loss: 1.4181 - val_accuracy: 0.5868\n",
      "Epoch 8/30\n",
      "4484/4484 [==============================] - 104s 23ms/step - loss: 1.1508 - accuracy: 0.6465 - val_loss: 1.4230 - val_accuracy: 0.5894\n",
      "Epoch 9/30\n",
      "4484/4484 [==============================] - 103s 23ms/step - loss: 1.1269 - accuracy: 0.6530 - val_loss: 1.4250 - val_accuracy: 0.5923\n",
      "Epoch 10/30\n",
      "4484/4484 [==============================] - 102s 23ms/step - loss: 1.1047 - accuracy: 0.6590 - val_loss: 1.4393 - val_accuracy: 0.5918\n",
      "Epoch 11/30\n",
      "4484/4484 [==============================] - 104s 23ms/step - loss: 1.0851 - accuracy: 0.6642 - val_loss: 1.4423 - val_accuracy: 0.5935\n",
      "Epoch 12/30\n",
      "4484/4484 [==============================] - 102s 23ms/step - loss: 1.0701 - accuracy: 0.6680 - val_loss: 1.4572 - val_accuracy: 0.5920\n",
      "Epoch 13/30\n",
      "4484/4484 [==============================] - 102s 23ms/step - loss: 1.0592 - accuracy: 0.6702 - val_loss: 1.4710 - val_accuracy: 0.5914\n",
      "Epoch 14/30\n",
      "4484/4484 [==============================] - 104s 23ms/step - loss: 1.0501 - accuracy: 0.6729 - val_loss: 1.4715 - val_accuracy: 0.5925\n",
      "Epoch 15/30\n",
      "4484/4484 [==============================] - 102s 23ms/step - loss: 1.0400 - accuracy: 0.6748 - val_loss: 1.4707 - val_accuracy: 0.5931\n",
      "Epoch 16/30\n",
      "4484/4484 [==============================] - 102s 23ms/step - loss: 1.0330 - accuracy: 0.6772 - val_loss: 1.4739 - val_accuracy: 0.5918\n",
      "Epoch 17/30\n",
      "4484/4484 [==============================] - 104s 23ms/step - loss: 1.0270 - accuracy: 0.6787 - val_loss: 1.4860 - val_accuracy: 0.5924\n",
      "Epoch 18/30\n",
      "4484/4484 [==============================] - 102s 23ms/step - loss: 1.0208 - accuracy: 0.6804 - val_loss: 1.4915 - val_accuracy: 0.5930\n",
      "Epoch 19/30\n",
      "4484/4484 [==============================] - 103s 23ms/step - loss: 1.0237 - accuracy: 0.6785 - val_loss: 1.4850 - val_accuracy: 0.5918\n",
      "Epoch 20/30\n",
      "4484/4484 [==============================] - 104s 23ms/step - loss: 1.0157 - accuracy: 0.6822 - val_loss: 1.4903 - val_accuracy: 0.5920\n",
      "Epoch 21/30\n",
      "4484/4484 [==============================] - 102s 23ms/step - loss: 1.0149 - accuracy: 0.6816 - val_loss: 1.4971 - val_accuracy: 0.5912\n",
      "Epoch 22/30\n",
      "4484/4484 [==============================] - 103s 23ms/step - loss: 1.0092 - accuracy: 0.6829 - val_loss: 1.5053 - val_accuracy: 0.5906\n",
      "Epoch 23/30\n",
      "4484/4484 [==============================] - 104s 23ms/step - loss: 1.0113 - accuracy: 0.6825 - val_loss: 1.5048 - val_accuracy: 0.5932\n",
      "Epoch 24/30\n",
      "4484/4484 [==============================] - 102s 23ms/step - loss: 1.0107 - accuracy: 0.6829 - val_loss: 1.5011 - val_accuracy: 0.5936\n",
      "Epoch 25/30\n",
      "4484/4484 [==============================] - 103s 23ms/step - loss: 1.0081 - accuracy: 0.6826 - val_loss: 1.5101 - val_accuracy: 0.5910\n",
      "Epoch 26/30\n",
      "4484/4484 [==============================] - 104s 23ms/step - loss: 1.0080 - accuracy: 0.6834 - val_loss: 1.5049 - val_accuracy: 0.5929\n",
      "Epoch 27/30\n",
      "4484/4484 [==============================] - 101s 23ms/step - loss: 1.0114 - accuracy: 0.6820 - val_loss: 1.5049 - val_accuracy: 0.5897\n",
      "Epoch 28/30\n",
      "4484/4484 [==============================] - 101s 23ms/step - loss: 1.0080 - accuracy: 0.6827 - val_loss: 1.5114 - val_accuracy: 0.5922\n",
      "Epoch 29/30\n",
      "4484/4484 [==============================] - 101s 23ms/step - loss: 1.0076 - accuracy: 0.6828 - val_loss: 1.5161 - val_accuracy: 0.5904\n",
      "Epoch 30/30\n",
      "2338/4484 [==============>...............] - ETA: 44s - loss: 0.9992 - accuracy: 0.6840"
     ]
    }
   ],
   "source": [
    "history = model.fit(predictors, labels, validation_split=0.2, batch_size=47, verbose=1, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc      = history.history['accuracy']\n",
    "val_acc  = history.history['val_accuracy']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b-o', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r--', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b-o', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r--', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "\n",
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
    "\n",
    "\n",
    "def prepare_input(text):\n",
    "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
    "    \n",
    "    for t, char in enumerate(text):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    \n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        \n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            return completion\n",
    "\n",
    "\n",
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    \n",
    "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSentence(text, words = 2):\n",
    "    textOG = text\n",
    "    text = text.lower()\n",
    "    \n",
    "    while len(text) < SEQUENCE_LENGTH:\n",
    "        text = ' ' + text\n",
    "    \n",
    "    text = text[-SEQUENCE_LENGTH:]\n",
    "    \n",
    "    for i in range(words):\n",
    "        text = text[-SEQUENCE_LENGTH:]\n",
    "        pred = predict_completions(text, 2)[0]\n",
    "        text = text + pred\n",
    "        textOG = textOG + pred\n",
    "        pass\n",
    "    \n",
    "    return textOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(genSentence(\"500 \", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(genSentence(\"Hilary \", 10))\n",
    "print(genSentence(\"Washington\", 10))\n",
    "print(genSentence(\"Today in\", 10))\n",
    "print(genSentence(\"The school\",13))\n",
    "print(genSentence(\"New York Times\", 10))\n",
    "print(genSentence(\"Make\", 10))\n",
    "print(genSentence(\"America\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
